
## Multi-client In-Memory Key/Value Datastore Server

The server supports single commands and transactions over a plain TCP socket connection. Both keys and values are UTF-8 strings.
It may potentially be used as a high performance cache.

_A transaction is a set of data modification commands that are updated in an “all or nothing” fashion – in that connecting clients see all the data modifications contained in a transaction that has been committed as an atomic operation._

### Commands (case insensitive) and parameters
* PUT [key] [value]
* GET [key]
* DEL [key]
* START
* COMMIT
* ROLLBACK
space is not allowed in `key`.

### Start the server
#### Directly
Make sure Python 3 is installed. Then,
```bash
python3 HausKVServer.py
```
The server will listen on port 9888.

#### In a docker container
Run the follow command to generate a docker image.
```bash
docker build -t haus-dapeng .
```
You may check whether the docker image has been correctly generated by running `docker image list`.
The following command runs the server inside a docker container:
```bash
docker run -p 9888:9888 haus-dapeng
```
You may add `-t` to the docker run command so that the output of the server is shown in real time.
In the above commands, `haus-dapeng` is the name of generated image, you may replace it with other small case strings you like.

---

### Connect to the Server

You can use `telnet`:

```bash
telnet localhost 9888
```

### Command and response formats
Commands are strings, while spaces are only significant inside `value` of command `PUT`. For example, <pre>`PUT   a    3 * 3 = 9 `</pre> will be interpreted as `PUT` value `3 * 3 = 9` to key `a`.

Server Responses to Commands
The server will return a JSON structure with the following keys:
* status – required, “Ok” or “Error”
* result – optional, result of a GET
* mesg - optional, additional context:  could be a human-readable message


### Examples of interaction on a client

```text
PUT a 1
{"status": "Ok"}
GET a
{"status": "Ok", "result": "1"}
START
GET most_popular_leader
{"status": "Ok", "result": "georgew"}
PUT georgew {"first_name": "George", "last_name": "Washington", "role": "President"}
{"status": "Ok"}
PUT winstonc {"first_name": "Winston", "last_name": "Churchill", "role": "Prime Minister"}
{"status": "Ok"}
GET georgew
{"status": "Ok", "result": "{\"first_name\": \"George\", \"last_name\": \"Washington\", \"role\": \"President\"}"}
COMMIT
```

---
## Development notes

_Note:  some assumptions or requirements have been deliberately omitted from the instructions.  Please take note of any assumptions you make in your solution, along with the rationale for taking those decisions – include such notes in the README.md file._

A KV store can be implemented using various data structures, B tree, skip list, etc, we may even use a RDBMS underneath. Here I chose dictionary/hash table to implement it.

Some high performance kv stores are free and avaiable, some are even open sourced, we may use them or modify the source code to fit our needs.

Either way, we have to understand our application scenarios and maintain the execution, let the software run in a healthy environment.

### Concerns in a production environment
- There is no requirements of work load, number of kv pairs, traffic of the requests, etc. They are critical design factors.
- If we use a hashtable, we better keep load factor under 70%. (Remember to factor in data growth in the production environment.)
- We don't persistence data to disk. In the future, what if we have to make the datastore larger? How to migrate the data? I assume we can tolerate data loss.
- If the data is too large and we may partition the data into multi datastores. Partitioning may work naturally with Haus.
- Since keys do not have Time To Live (TTL), its memory footprint won't reduce if we don't run DEL.
- It may run out of memory (OOM) and get killed by operation system, if the data size keeps growing.
- Is there a time gap in which we can restart the kv store, to clean up the memory, say, in midnights?

### Multi threading
- The requirement of supporting multiple clients means multi threads and concurrency control.
- Python has GIL. A online search returned that Python dict is not thread safe. I explicitly sync operations on it.
- We could fine tune the granularity of the concurrency control, say, a transaction on key `a` does not interfere with another transaction on key `b` . For this coding assignment, I lock the whole dict. No premature optimization.

### Exception control
- If one PUT fails, we should rollback all other PUTs? Eg, if we buffer many PUTs in a transaction which uses up the memory, some PUTs will succeed but some others will fail.
- Don't consider this scenario, because a hash table already has too many collisions and the performance becomes terrible. This should not happen in a good production environment.
- Even if we try, we cannot guarantee rollback always succeeds, because the memory could be used up by another client at the time.

### Encoding and communication
- TCP transfers bytes. UTF8 rendering can be a visual issue, e.g., `\u8bf4` is Chinese character `说`. Since Haus is an international company, font rendering/locale is important. Luckily, rest assured, there is no data loss.
- since responses are in JSON format, to make the server work for a program client, we have to escape values. I choose `json.dumps()`.

### Docker and port
- If we will put the code in a docker, the listening port does not matter. To make test easier, I hard coded 9888 in the code.

### Misc
- del is a Python reserved keyword, so in the code I use delete. I read it as "make sure the key is not in the store", so we don't raise an error if the key is not found, we treat it as a no-op.
– if the client buffers transaction context before seeing COMMIT when the transaction is sent to the server, the server can handle all requests atomically

---

## Project Development Plan
After thinking over these details, I thought about how to implement the project.

### Major steps
1. Create a server that can cater multi clients, this is a standard boilerplate
2. Create a Docker, a boilerplate too (we may use docker-compose to define network ports)
3. Implement the key-value datastore, which is the core, consisting of a globle singleton dict. Make it easy for unit test.
4. Implement a driver that translates text command to method calls and wrap up responses in JSON format
5. Test
   1. for boilerplates, we manually test them along with the development
   2. for the kv store, we need test its input, output, execution logic, etc.
   3. integration test, in a near production environment, and using multiple threads

My development followed these big steps.
For a big project in real life, it often makes sense to split these tasks into parallel workstreams and assign them to different engineers to accelerate delivery.
